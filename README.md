# ViewStats

## 📚 Project Overview

**ViewStats** is an AI-powered semantic video classification and exploration platform. It processes a dataset of over **124,000 YouTube videos**, extracting **contextually-derived topics** and enabling users to perform **semantic search and taxonomy-based navigation** through a complete full-stack application.

### ✅ Highlights

- AI-generated **multi-label classification** for both **videos** and **channels**
- Derivation of a **custom hierarchical taxonomy** based on content, using LLMs (OpenAI GPT-4, Google Gemini)
- Real-time **semantic search engine** using vector embeddings and Qdrant
- Full-stack solution including **FastAPI backend**, **Next.js frontend**, and a robust **Python data processing pipeline**
- Designed with **modularity**, **scalability**, and **transparency**
- **Automated, auditable, and checkpointed data processing pipeline** (see `scripts/`)

---

## 🔧 Technologies Used

- **Backend**: FastAPI (Python 3.11)
- **Frontend**: Next.js + TailwindCSS (React-based)
- **Embeddings**: `all-MiniLM-L6-v2` via `sentence-transformers` (OpenAI and Gemini optional for topic classification)
- **Vector Store**: Qdrant
- **Topic Generation**: OpenAI GPT-4, Google Gemini
- **Infrastructure**: Docker & Docker Compose
- **Data Processing Pipeline**: Python scripts (see below)

---

## 🧠 Core Features

### 🧩 Hierarchical Topic Derivation
- Topics and subtopics are generated by an **LLM (GPT-4, Gemini, etc.)** analyzing the full textual content of each video
- No pre-defined category list; the **taxonomy is emergent**
- Stored as a dynamic, navigable **JSON tree**

### 📊 Semantic Indexing in Qdrant
- Embeddings are computed from a combination of title, description, and transcript
- Payloads include video/channel metadata, topic paths, tags, and other attributes
- Videos are indexed in Qdrant for **hybrid filtering and similarity search**

### 🔍 Semantic Search Engine
- Users can perform:
  - Free-text search (e.g., "Magnus Carlsen")
  - Filtered search by hierarchical topic
  - Combined vector + keyword search
- Results are ranked by **semantic similarity** and **contextual match**

### 🌳 Taxonomy Browser
- Full topic tree exposed as a JSON-based API
- Dynamically generated from the LLM-classified topic paths
- Enables hierarchical drill-down via frontend interface

### 📡 Modular API Design
- `/search`: vector-based semantic search (com filtro de tópico)
- `/taxonomy`: explore topic tree (JSON)
- `/video/{id}`: retrieve video metadata
- `/channel/{id}`: retrieve channel-level classification
- `/qdrant/insert`: add vectors and payloads into Qdrant
- `/upload-csv`: ingest dataset samples or video metadata

---

## 📁 Project Structure

```
viewstats/
├── backend/
│   ├── Dockerfile
│   ├── requirements.txt
│   └── app/
│       ├── main.py
│       ├── api/                # FastAPI endpoints (search, taxonomy, video, channel)
│       ├── core/               # Configs, environment, logger
│       ├── services/           # Embedding, Qdrant, LLM, taxonomy
│       ├── models/             # Pydantic request/response schemas
│       ├── utils/              # Text cleaning, helpers
│       └── data/               # taxonomy.json, sample datasets
├── frontend/
│   ├── Dockerfile
│   ├── package.json
│   ├── app/                    # Next.js app directory
│   ├── components/             # React components
│   ├── hooks/                  # React hooks
│   ├── lib/                    # Utilities and types
│   ├── public/
│   │   └── images/             # Static images
│   └── styles/                 # CSS/SCSS files
├── scripts/                    # Data processing pipeline (see below)
│   ├── main.py                 # Orchestrates the full pipeline
│   ├── config.py               # Centralized configuration
│   ├── data_handler.py         # Data loading and cleaning
│   ├── llm_processor.py        # LLM-based metadata extraction
│   ├── taxonomy_builder.py     # Taxonomy consolidation
│   ├── taxonomy_draft_builder.py
│   ├── taxonomy_refiner.py
│   ├── taxonomy_mapper.py
│   ├── result_handler.py
│   ├── indexer.py              # Qdrant vector indexing
│   ├── embedding_service.py
│   ├── requirements.txt
│   └── input/                  # Input CSVs
├── docker-compose.yaml
├── .env
└── README.md
```

---

## 🛠️ Data Processing Pipeline (`scripts/`)

The `scripts/` directory contains a robust, modular pipeline for processing and enriching video data before it is served by the backend and frontend. **This pipeline is responsible for:**

- Loading and cleaning raw video data (CSV)
- Extracting rich metadata from each video using LLMs (description, named entities, intention, hierarchical topics)
- Building and refining a hierarchical taxonomy of topics (LLM-driven, two-pass refinement)
- Mapping each video to taxonomy IDs
- Indexing all videos in Qdrant with semantic embeddings and rich payloads
- Saving checkpoints and logs for full auditability and fault tolerance

**Pipeline Steps:**
1. **Data Preparation:** Load and clean CSV data (`data_handler.py`)
2. **LLM Processing:** Extract metadata and topics for each video (`llm_processor.py`)
3. **Draft Taxonomy:** Aggregate all topic paths into a draft taxonomy (`taxonomy_draft_builder.py`)
4. **Taxonomy Refinement:** Use LLM to merge and re-parent topics, producing a canonical taxonomy (`taxonomy_refiner.py`)
5. **Taxonomy Consolidation:** Save the final taxonomy for API use (`taxonomy_builder.py`)
6. **Mapping:** Map each video to taxonomy IDs (`taxonomy_mapper.py`)
7. **Indexing:** Index videos in Qdrant with embeddings and metadata (`indexer.py`)
8. **Reporting:** Output logs, cost, and token usage for each step

**To run the full pipeline:**
```bash
cd scripts
python main.py
```
- All intermediate and final artifacts are saved in `scripts/data/`
- Checkpoints allow for safe resumption in case of interruption

---

## 🚀 How to Run

### 1. Start the Full Stack (Backend + Qdrant + Frontend)
```bash
docker-compose up --build
```

### 2. Access the Services

* Backend API: [http://localhost:8000](http://localhost:8000)
* Qdrant UI/API: [http://localhost:6333](http://localhost:6333)
* Frontend UI: [http://localhost:3000](http://localhost:3000)

---

## 🧪 API Endpoints

| Endpoint         | Method | Description                             |
| ---------------- | ------ | --------------------------------------- |
| `/`              | GET    | Health check                            |
| `/upload-csv`    | POST   | Upload CSV file and get schema          |
| `/qdrant/insert` | POST   | Insert vector + metadata into Qdrant    |
| `/search`        | POST   | Semantic search with query and filters  |
| `/taxonomy`      | GET    | Returns the full topic hierarchy (JSON) |
| `/video/{id}`    | GET    | Retrieve video payload from Qdrant      |
| `/channel/{id}`  | GET    | Retrieve channel-level classification   |

### Example: `/search` (POST)
**Request:**
```json
{
  "query": "FastAPI",
  "topic_filter": "Tecnologia > Programação > Python",
  "top_k": 5
}
```
**Response:**
```json
{
  "results": [
    {
      "id": "video1",
      "score": 0.92,
      "title": "Como usar FastAPI",
      "description": "Tutorial completo de FastAPI para APIs modernas.",
      "topics_path": ["Tecnologia > Programação > Python"]
    }
  ]
}
```

### Example: `/taxonomy` (GET)
**Response:**
```json
{
  "taxonomy": [
    {"name": "Tecnologia", "_children": [
      {"name": "Programação", "_children": [
        {"name": "Python", "_children": []}
      ]}
    ]}
  ]
}
```

### Example: `/video/{id}` (GET)
**Response:**
```json
{
  "id": "abc123",
  "title": "Exemplo de vídeo",
  "description": "Descrição do vídeo de exemplo.",
  "topics_path": ["Tecnologia > Programação > Python"],
  "channel_id": "canal123"
}
```

### Example: `/channel/{id}` (GET)
**Response:**
```json
{
  "id": "canal123",
  "name": "Canal Exemplo",
  "topics": ["Tecnologia > Programação", "Educação > Tutoriais"]
}
```

---

## 🧪 LLM Prompt Strategy (for Topic Derivation)

Topics are derived by prompting the LLM (OpenAI or Gemini) with each video's text. Example prompt:

```
Given the following video metadata, return up to 3 hierarchical topic paths in the format:
"Topic > Subtopic > Subsubtopic"

Title: "How to Build a Chatbot with GPT-4"
Description: "A full walkthrough using OpenAI's GPT API"
Transcript excerpt: "...first, choose your system prompt..."
```

→ Output:

```json
["Technology > AI > Chatbots", "Software > Development > NLP"]
```

---

## 🎯 Evaluation Criteria (from the original challenge)

| Area                         | Weight |
| ---------------------------- | ------ |
| Classification Accuracy      | 30%    |
| Semantic Search Relevance    | 30%    |
| Backend/API Design           | 15%    |
| Frontend Functionality       | 10%    |
| Code Quality & Documentation | 10%    |

✅ Bonus points included for:

* Abbreviation handling (e.g., "NBA" = "National Basketball Association")
* Autocomplete suggestions
* Topic co-occurrence graphs
* Faceted filtering in the UI

---

## 📦 Dependencies

* Python 3.11
* FastAPI, Uvicorn, Pydantic
* `sentence-transformers` (`all-MiniLM-L6-v2`)
* `qdrant-client`
* OpenAI (opcional, para classificação de tópicos)
* Google Gemini (opcional, para classificação de tópicos)
* Node.js 18+ (Dockerized)
* React, Next.js, TailwindCSS

---

## 🔐 Notes

* This project is covered by **NDA** and must not be shared publicly.
* Designed for completion in **24–48 hours** as a take-home challenge.
* Up to $100 in API costs may be reimbursed if documented.

---

## 📝 Deliverables

* ✅ Source code (backend + optional frontend)
* ✅ This updated README with decisions and architecture
* ✅ Prompting strategy for topic generation
* ✅ API documentation (com exemplos)
* ✅ (Optional) Loom walkthrough or screenshots
* ✅ (Optional) Deployed version (not required)

---

## 📈 Future Work

* Improve taxonomy tree with LLM + graph analytics
* Add topic co-occurrence visualizations (GraphRAG-style)
* Typeahead/autocomplete in search
* RAG-based hybrid search augmentation (LLM + embeddings)
* Video clustering and personalized recommendations

---

## 📬 Submission

Send your GitHub repo and documentation to:

* [nagesh@mrbeastyoutube.com](mailto:nagesh@mrbeastyoutube.com)
* [byronm@mrbeastyoutube.com](mailto:byronm@mrbeastyoutube.com)
* [nicolas@viewstats.com](mailto:nicolas@viewstats.com)

---

## © License

This project is provided solely for evaluation under NDA and is not to be shared or published publicly.
