# ViewStats

## ğŸ“š Project Overview

**ViewStats** is an AI-powered semantic video classification and exploration platform. It processes a dataset of over **124,000 YouTube videos**, extracting **contextually-derived topics** and enabling users to perform **semantic search and taxonomy-based navigation** through a complete full-stack application.

### âœ… Highlights

- AI-generated **multi-label classification** for both **videos** and **channels**
- Derivation of a **custom hierarchical taxonomy** based on content, using LLMs (OpenAI GPT-4, Google Gemini)
- Real-time **semantic search engine** using vector embeddings and Qdrant
- Full-stack solution including **FastAPI backend**, **Next.js frontend**, and a robust **Python data processing pipeline**
- Designed with **modularity**, **scalability**, and **transparency**
- **Automated, auditable, and checkpointed data processing pipeline** (see `scripts/`)

---

## ğŸ”§ Technologies Used

- **Backend**: FastAPI (Python 3.11)
- **Frontend**: Next.js + TailwindCSS (React-based)
- **Embeddings**: `all-MiniLM-L6-v2` via `sentence-transformers` (OpenAI and Gemini optional for topic classification)
- **Vector Store**: Qdrant
- **Topic Generation**: OpenAI GPT-4, Google Gemini
- **Infrastructure**: Docker & Docker Compose
- **Data Processing Pipeline**: Python scripts (see below)

---

## ğŸ§  Core Features

### ğŸ§© Hierarchical Topic Derivation
- Topics and subtopics are generated by an **LLM (GPT-4, Gemini, etc.)** analyzing the full textual content of each video
- No pre-defined category list; the **taxonomy is emergent**
- Stored as a dynamic, navigable **JSON tree**

### ğŸ“Š Semantic Indexing in Qdrant
- Embeddings are computed from a combination of title, description, and transcript
- Payloads include video/channel metadata, topic paths, tags, and other attributes
- Videos are indexed in Qdrant for **hybrid filtering and similarity search**

### ğŸ” Semantic Search Engine
- Users can perform:
  - Free-text search (e.g., "Magnus Carlsen")
  - Filtered search by hierarchical topic
  - Combined vector + keyword search
- Results are ranked by **semantic similarity** and **contextual match**

### ğŸŒ³ Taxonomy Browser
- Full topic tree exposed as a JSON-based API
- Dynamically generated from the LLM-classified topic paths
- Enables hierarchical drill-down via frontend interface

### ğŸ“¡ Modular API Design
- `/search`: vector-based semantic search (com filtro de tÃ³pico)
- `/taxonomy`: explore topic tree (JSON)
- `/video/{id}`: retrieve video metadata
- `/channel/{id}`: retrieve channel-level classification
- `/qdrant/insert`: add vectors and payloads into Qdrant
- `/upload-csv`: ingest dataset samples or video metadata

---

## ğŸ“ Project Structure

```
viewstats/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ api/                # FastAPI endpoints (search, taxonomy, video, channel)
â”‚       â”œâ”€â”€ core/               # Configs, environment, logger
â”‚       â”œâ”€â”€ services/           # Embedding, Qdrant, LLM, taxonomy
â”‚       â”œâ”€â”€ models/             # Pydantic request/response schemas
â”‚       â”œâ”€â”€ utils/              # Text cleaning, helpers
â”‚       â””â”€â”€ data/               # taxonomy.json, sample datasets
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ app/                    # Next.js app directory
â”‚   â”œâ”€â”€ components/             # React components
â”‚   â”œâ”€â”€ hooks/                  # React hooks
â”‚   â”œâ”€â”€ lib/                    # Utilities and types
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ images/             # Static images
â”‚   â””â”€â”€ styles/                 # CSS/SCSS files
â”œâ”€â”€ scripts/                    # Data processing pipeline (see below)
â”‚   â”œâ”€â”€ main.py                 # Orchestrates the full pipeline
â”‚   â”œâ”€â”€ config.py               # Centralized configuration
â”‚   â”œâ”€â”€ data_handler.py         # Data loading and cleaning
â”‚   â”œâ”€â”€ llm_processor.py        # LLM-based metadata extraction
â”‚   â”œâ”€â”€ taxonomy_builder.py     # Taxonomy consolidation
â”‚   â”œâ”€â”€ taxonomy_draft_builder.py
â”‚   â”œâ”€â”€ taxonomy_refiner.py
â”‚   â”œâ”€â”€ taxonomy_mapper.py
â”‚   â”œâ”€â”€ result_handler.py
â”‚   â”œâ”€â”€ indexer.py              # Qdrant vector indexing
â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ input/                  # Input CSVs
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Data Processing Pipeline (`scripts/`)

The `scripts/` directory contains a robust, modular pipeline for processing and enriching video data before it is served by the backend and frontend. **This pipeline is responsible for:**

- Loading and cleaning raw video data (CSV)
- Extracting rich metadata from each video using LLMs (description, named entities, intention, hierarchical topics)
- Building and refining a hierarchical taxonomy of topics (LLM-driven, two-pass refinement)
- Mapping each video to taxonomy IDs
- Indexing all videos in Qdrant with semantic embeddings and rich payloads
- Saving checkpoints and logs for full auditability and fault tolerance

**Pipeline Steps:**
1. **Data Preparation:** Load and clean CSV data (`data_handler.py`)
2. **LLM Processing:** Extract metadata and topics for each video (`llm_processor.py`)
3. **Draft Taxonomy:** Aggregate all topic paths into a draft taxonomy (`taxonomy_draft_builder.py`)
4. **Taxonomy Refinement:** Use LLM to merge and re-parent topics, producing a canonical taxonomy (`taxonomy_refiner.py`)
5. **Taxonomy Consolidation:** Save the final taxonomy for API use (`taxonomy_builder.py`)
6. **Mapping:** Map each video to taxonomy IDs (`taxonomy_mapper.py`)
7. **Indexing:** Index videos in Qdrant with embeddings and metadata (`indexer.py`)
8. **Reporting:** Output logs, cost, and token usage for each step

**To run the full pipeline:**
```bash
cd scripts
python main.py
```
- All intermediate and final artifacts are saved in `scripts/data/`
- Checkpoints allow for safe resumption in case of interruption

---

## ğŸš€ How to Run

### 1. Start the Full Stack (Backend + Qdrant + Frontend)
```bash
docker-compose up --build
```

### 2. Access the Services

* Backend API: [http://localhost:8000](http://localhost:8000)
* Qdrant UI/API: [http://localhost:6333](http://localhost:6333)
* Frontend UI: [http://localhost:3000](http://localhost:3000)

---

## ğŸ§ª API Endpoints

| Endpoint         | Method | Description                             |
| ---------------- | ------ | --------------------------------------- |
| `/`              | GET    | Health check                            |
| `/upload-csv`    | POST   | Upload CSV file and get schema          |
| `/qdrant/insert` | POST   | Insert vector + metadata into Qdrant    |
| `/search`        | POST   | Semantic search with query and filters  |
| `/taxonomy`      | GET    | Returns the full topic hierarchy (JSON) |
| `/video/{id}`    | GET    | Retrieve video payload from Qdrant      |
| `/channel/{id}`  | GET    | Retrieve channel-level classification   |

### Example: `/search` (POST)
**Request:**
```json
{
  "query": "FastAPI",
  "topic_filter": "Tecnologia > ProgramaÃ§Ã£o > Python",
  "top_k": 5
}
```
**Response:**
```json
{
  "results": [
    {
      "id": "video1",
      "score": 0.92,
      "title": "Como usar FastAPI",
      "description": "Tutorial completo de FastAPI para APIs modernas.",
      "topics_path": ["Tecnologia > ProgramaÃ§Ã£o > Python"]
    }
  ]
}
```

### Example: `/taxonomy` (GET)
**Response:**
```json
{
  "taxonomy": [
    {"name": "Tecnologia", "_children": [
      {"name": "ProgramaÃ§Ã£o", "_children": [
        {"name": "Python", "_children": []}
      ]}
    ]}
  ]
}
```

### Example: `/video/{id}` (GET)
**Response:**
```json
{
  "id": "abc123",
  "title": "Exemplo de vÃ­deo",
  "description": "DescriÃ§Ã£o do vÃ­deo de exemplo.",
  "topics_path": ["Tecnologia > ProgramaÃ§Ã£o > Python"],
  "channel_id": "canal123"
}
```

### Example: `/channel/{id}` (GET)
**Response:**
```json
{
  "id": "canal123",
  "name": "Canal Exemplo",
  "topics": ["Tecnologia > ProgramaÃ§Ã£o", "EducaÃ§Ã£o > Tutoriais"]
}
```

---

## ğŸ§ª LLM Prompt Strategy (for Topic Derivation)

Topics are derived by prompting the LLM (OpenAI or Gemini) with each video's text. Example prompt:

```
Given the following video metadata, return up to 3 hierarchical topic paths in the format:
"Topic > Subtopic > Subsubtopic"

Title: "How to Build a Chatbot with GPT-4"
Description: "A full walkthrough using OpenAI's GPT API"
Transcript excerpt: "...first, choose your system prompt..."
```

â†’ Output:

```json
["Technology > AI > Chatbots", "Software > Development > NLP"]
```

---

## ğŸ¯ Evaluation Criteria (from the original challenge)

| Area                         | Weight |
| ---------------------------- | ------ |
| Classification Accuracy      | 30%    |
| Semantic Search Relevance    | 30%    |
| Backend/API Design           | 15%    |
| Frontend Functionality       | 10%    |
| Code Quality & Documentation | 10%    |

âœ… Bonus points included for:

* Abbreviation handling (e.g., "NBA" = "National Basketball Association")
* Autocomplete suggestions
* Topic co-occurrence graphs
* Faceted filtering in the UI

---

## ğŸ“¦ Dependencies

* Python 3.11
* FastAPI, Uvicorn, Pydantic
* `sentence-transformers` (`all-MiniLM-L6-v2`)
* `qdrant-client`
* OpenAI (opcional, para classificaÃ§Ã£o de tÃ³picos)
* Google Gemini (opcional, para classificaÃ§Ã£o de tÃ³picos)
* Node.js 18+ (Dockerized)
* React, Next.js, TailwindCSS

---

## ğŸ” Notes

* This project is covered by **NDA** and must not be shared publicly.
* Designed for completion in **24â€“48 hours** as a take-home challenge.
* Up to $100 in API costs may be reimbursed if documented.

---

## ğŸ“ Deliverables

* âœ… Source code (backend + optional frontend)
* âœ… This updated README with decisions and architecture
* âœ… Prompting strategy for topic generation
* âœ… API documentation (com exemplos)
* âœ… (Optional) Loom walkthrough or screenshots
* âœ… (Optional) Deployed version (not required)

---

## ğŸ“ˆ Future Work

* Improve taxonomy tree with LLM + graph analytics
* Add topic co-occurrence visualizations (GraphRAG-style)
* Typeahead/autocomplete in search
* RAG-based hybrid search augmentation (LLM + embeddings)
* Video clustering and personalized recommendations

---

## ğŸ“¬ Submission

Send your GitHub repo and documentation to:

* [nagesh@mrbeastyoutube.com](mailto:nagesh@mrbeastyoutube.com)
* [byronm@mrbeastyoutube.com](mailto:byronm@mrbeastyoutube.com)
* [nicolas@viewstats.com](mailto:nicolas@viewstats.com)

---

## Â© License

This project is provided solely for evaluation under NDA and is not to be shared or published publicly.
